{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323c1c36",
   "metadata": {},
   "source": [
    "### Initializing libraries and declaring some global libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sqlite3\n",
    "import joblib\n",
    "\n",
    "DATABASE_PATH = 'dataset/FPA_FOD_20170508.sqlite'\n",
    "NUMERICAL_COLS = ['DISCOVERY_DATE', 'DISCOVERY_DOY', 'CONT_DATE', 'CONT_DOY',\n",
    "                  'FIRE_SIZE', 'LATITUDE', 'LONGITUDE', 'OWNER_CODE']\n",
    "TARGET_COL = 'STAT_CAUSE_CODE'\n",
    "DATA_SAMPLE_SIZE = 2000\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234848e1",
   "metadata": {},
   "source": [
    "### Loading data and then preprocessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82756500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(database_path, table_name, sample_size, random_state):\n",
    "    connection = sqlite3.connect(database_path)\n",
    "    data = pd.read_sql_query(f\"SELECT * FROM {table_name}\", connection)\n",
    "    connection.close()\n",
    "    return data.sample(n=sample_size, random_state=random_state)\n",
    "\n",
    "def preprocess_data(data, target_col, numerical_cols, balance_classes=False):\n",
    "    X = data.drop(columns=[target_col])\n",
    "    y = data[target_col]\n",
    "    non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for col in non_numeric_cols:\n",
    "        le = LabelEncoder()\n",
    "        X[col] = X[col].fillna('')\n",
    "        X[col] = X[col].apply(lambda x: str(x).encode('ascii', 'ignore').decode('ascii'))\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "    \n",
    "    X = X.fillna(0)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    X[numerical_cols] = min_max_scaler.fit_transform(X[numerical_cols])\n",
    "    std_scaler = StandardScaler()\n",
    "    X[numerical_cols] = std_scaler.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    if balance_classes:\n",
    "        smote = SMOTE(random_state=RANDOM_STATE)\n",
    "        X, y = smote.fit_resample(X, y)\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE), X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94257046",
   "metadata": {},
   "source": [
    "### Training the model and saving them as pkl files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f62c340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return model, y_pred, accuracy\n",
    "\n",
    "def save_results_and_models(X, y, y_test, y_preds, models, prefix):\n",
    "    joblib.dump((X, y, y_test, y_preds), f\"pickle_files/{prefix}_results.pkl\")\n",
    "    for model_name, model in models.items():\n",
    "        joblib.dump(model, f\"pickle_files/{model_name.lower()}_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d48de",
   "metadata": {},
   "source": [
    "### Main code execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73cab1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (RandomForest, class_balance): 0.96\n",
      "Accuracy (SVM, class_balance): 0.16\n",
      "Accuracy (KNN, class_balance): 0.48\n",
      "Accuracy (RandomForest, no_balance): 0.89\n",
      "Accuracy (SVM, no_balance): 0.21\n",
      "Accuracy (KNN, no_balance): 0.38\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = load_data(DATABASE_PATH, \"Fires\", DATA_SAMPLE_SIZE, RANDOM_STATE)\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "        \"SVM\": SVC(random_state=RANDOM_STATE),\n",
    "        \"KNN\": KNeighborsClassifier()\n",
    "    }\n",
    "    \n",
    "    y_preds = {}\n",
    "    for balance_classes in [True, False]:\n",
    "        scenario = \"class_balance\" if balance_classes else \"no_balance\"\n",
    "        (X_train, X_test, y_train, y_test), X_processed, y_processed = preprocess_data(\n",
    "            data, TARGET_COL, NUMERICAL_COLS, balance_classes=balance_classes\n",
    "        )\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            trained_model, y_pred, accuracy = train_and_evaluate_model(\n",
    "                model, X_train, X_test, y_train, y_test\n",
    "            )\n",
    "            models[model_name] = trained_model\n",
    "            y_preds[model_name] = y_pred\n",
    "            print(f\"Accuracy ({model_name}, {scenario}): {accuracy:.2f}\")\n",
    "        save_results_and_models(X_processed, y_processed, y_test, y_preds, models, scenario)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analys_visu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
